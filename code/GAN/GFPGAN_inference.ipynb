{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJtKN6ANUADM"
      },
      "source": [
        "# GFPGAN Inference Demo\n",
        "\n",
        "https://github.com/TencentARC/GFPGAN\n",
        "\n",
        "### (No colorization; No CUDA extensions required)\n",
        "\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2101.04061)\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/TencentARC/GFPGAN?style=social)](https://github.com/TencentARC/GFPGAN)\n",
        "[![download](https://img.shields.io/github/downloads/TencentARC/GFPGAN/total.svg)](https://github.com/TencentARC/GFPGAN/releases)\n",
        "\n",
        "## GFPGAN - Towards Real-World Blind Face Restoration with Generative Facial Prior\n",
        "\n",
        "GFPGAN is a blind face restoration algorithm towards real-world face images. <br>\n",
        "It leverages the generative face prior in a pre-trained GAN (*e.g.*, StyleGAN2) to restore realistic faces while precerving fidelity. <br>\n",
        "\n",
        "If you want to use the paper model, please go to this [Colab Demo](https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing) for GFPGAN <a href=\"https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"google colab logo\"></a>.\n",
        "\n",
        "**Limitations**: GFPGAN could not handle all the low-quality faces in the real world. Therefore, it may fail on your own cases.\n",
        "\n",
        "###Enjoy! :-)\n",
        "\n",
        "<img src=\"https://xinntao.github.io/projects/GFPGAN_src/gfpgan_teaser.jpg\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY1Zbo3uUkXg"
      },
      "source": [
        "# 1. Preparations\n",
        "Before start, make sure that you choose\n",
        "* Runtime Type = Python 3\n",
        "* Hardware Accelerator = GPU\n",
        "\n",
        "in the **Runtime** menu -> **Change runtime type**\n",
        "\n",
        "Then, we clone the repository, set up the envrironment, and download the pre-trained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwH2ifWEYEfJ",
        "outputId": "65c2f202-34d8-4f50-b892-1b20ae769f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'GFPGAN'...\n",
            "remote: Enumerating objects: 527, done.\u001b[K\n",
            "remote: Counting objects: 100% (212/212), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 527 (delta 170), reused 154 (delta 154), pack-reused 315 (from 2)\u001b[K\n",
            "Receiving objects: 100% (527/527), 5.38 MiB | 14.41 MiB/s, done.\n",
            "Resolving deltas: 100% (281/281), done.\n",
            "/content/GFPGAN\n",
            "Collecting basicsr\n",
            "  Downloading basicsr-1.4.2.tar.gz (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m818.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from basicsr)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from basicsr) (1.0.0)\n",
            "Collecting lmdb (from basicsr)\n",
            "  Downloading lmdb-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from basicsr) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from basicsr) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from basicsr) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.32.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from basicsr) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from basicsr) (1.15.3)\n",
            "Collecting tb-nightly (from basicsr)\n",
            "  Downloading tb_nightly-2.20.0a20250716-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from basicsr) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from basicsr) (4.67.1)\n",
            "Collecting yapf (from basicsr)\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7->basicsr)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7->basicsr)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7->basicsr)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7->basicsr)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7->basicsr)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7->basicsr)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7->basicsr)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7->basicsr)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7->basicsr)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7->basicsr)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7->basicsr) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (2025.7.14)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (3.1.3)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->basicsr) (4.3.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tb-nightly->basicsr) (3.0.2)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        }
      ],
      "source": [
        "# Clone GFPGAN and enter the GFPGAN folder\n",
        "%cd /content\n",
        "!rm -rf GFPGAN\n",
        "!git clone https://github.com/TencentARC/GFPGAN.git\n",
        "%cd GFPGAN\n",
        "\n",
        "# Set up the environment\n",
        "# Install basicsr - https://github.com/xinntao/BasicSR\n",
        "# We use BasicSR for both training and inference\n",
        "!pip install basicsr\n",
        "# Install facexlib - https://github.com/xinntao/facexlib\n",
        "# We use face detection and face restoration helper in the facexlib package\n",
        "!pip install facexlib\n",
        "# Install other depencencies\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "!pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "# Download the pre-trained model\n",
        "# !wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models\n",
        "# Now we use the V1.3 model for the demo\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLPuPUguW0we"
      },
      "outputs": [],
      "source": [
        "!ls -laSh experiments/pretrained_models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-8JxpPwg4Xz"
      },
      "source": [
        "# 2. Upload Images / Use the demo images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdMZYp0T7NAy"
      },
      "outputs": [],
      "source": [
        "# # upload your own images\n",
        "# import os\n",
        "# from google.colab import files\n",
        "# import shutil\n",
        "\n",
        "# upload_folder = 'inputs/upload'\n",
        "\n",
        "# if os.path.isdir(upload_folder):\n",
        "#     shutil.rmtree(upload_folder)\n",
        "# os.mkdir(upload_folder)\n",
        "\n",
        "# # upload images\n",
        "# uploaded = files.upload()\n",
        "# for filename in uploaded.keys():\n",
        "#   dst_path = os.path.join(upload_folder, filename)\n",
        "#   print(f'move {filename} to {dst_path}')\n",
        "#   shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZUYDlMeXKe"
      },
      "source": [
        "### Using our images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6CkQ2x-eSjH"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "upload_folder = 'inputs/upload'\n",
        "\n",
        "!git clone https://github.com/fum-cs/dl-fall-2023.git\n",
        "src = 'dl/code/images'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.makedirs(upload_folder, exist_ok=True)\n",
        "for file in os.listdir (src):\n",
        "    shutil.copy2(os.path.join (src, file), upload_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGHc73Up70ZA"
      },
      "source": [
        "## 3. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmQVC3s97z4z"
      },
      "outputs": [],
      "source": [
        "# Now we use the GFPGAN to restore the above low-quality images\n",
        "# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n",
        "# You can find the different models in https://github.com/TencentARC/GFPGAN#european_castle-model-zoo\n",
        "!rm -rf results\n",
        "!python inference_gfpgan.py -i inputs/upload -o results -v 1.3 -s 2 --bg_upsampler realesrgan\n",
        "\n",
        "# Usage: python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2 [options]...\n",
        "#\n",
        "#  -h                   show this help\n",
        "#  -i input             Input image or folder. Default: inputs/whole_imgs\n",
        "#  -o output            Output folder. Default: results\n",
        "#  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3. Default: 1.3\n",
        "#  -s upscale           The final upsampling scale of the image. Default: 2\n",
        "#  -bg_upsampler        background upsampler. Default: realesrgan\n",
        "#  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400\n",
        "#  -suffix              Suffix of the restored faces\n",
        "#  -only_center_face    Only restore the center face\n",
        "#  -aligned             Input are aligned faces\n",
        "#  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto\n",
        "\n",
        "!ls results/cmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkF8VAiF7-PY"
      },
      "source": [
        "## 4. Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIeL_NJO8A3B"
      },
      "outputs": [],
      "source": [
        "# We first visualize the cropped faces\n",
        "# The left are the inputs images; the right are the results of GFPGAN\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('GFPGAN output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# display each image in the upload folder\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'results/cropped_faces'\n",
        "result_folder = 'results/restored_faces'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn_2ylqP9qXY"
      },
      "outputs": [],
      "source": [
        "# We then visualize the whole image\n",
        "# The left are the inputs images; the right are the results of GFPGAN\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('GFPGAN output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# display each image in the upload folder\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'inputs/upload'\n",
        "result_folder = 'results/restored_imgs'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR7VEBEb8slX"
      },
      "source": [
        "## 5. Download results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuBCgeH08tdn"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "# download the result\n",
        "!ls results\n",
        "print('Download results')\n",
        "os.system('zip -r download.zip results')\n",
        "files.download(\"download.zip\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RJtKN6ANUADM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}